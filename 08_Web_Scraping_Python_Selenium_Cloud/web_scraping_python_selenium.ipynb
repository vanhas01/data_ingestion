{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sized-physiology",
   "metadata": {},
   "source": [
    "# Web Scraping with Python and Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-destination",
   "metadata": {},
   "source": [
    "## Libraries and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from prettytable import from_csv\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Set up Chrome options\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# Path to ChromeDriver\n",
    "service = Service('/usr/local/bin/chromedriver')\n",
    "# service = Service(executable_path=r'C:\\Tools\\chromedriver\\chromedriver.exe')\n",
    "\n",
    "# Settings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Current working directory\n",
    "print(f'Current working directory: {os.getcwd()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-breath",
   "metadata": {},
   "source": [
    "## Import a list with user agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste mit User-Agents f√ºr Rotation\n",
    "ua_path = \"user_agents.txt\"\n",
    "ua_list = [line.rstrip('\\n') for line in open(ua_path)]\n",
    "ua_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-hanging",
   "metadata": {},
   "source": [
    "## Chrome headless mode (without graphical user interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the driver\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Website to scrape\n",
    "driver.get('https://store.dji.com')\n",
    "\n",
    "# Get current url\n",
    "print(driver.current_url)\n",
    "\n",
    "# Return the full page HTML code\n",
    "# print(driver.page_source)\n",
    "\n",
    "# Gets the page's title\n",
    "print(driver.title)\n",
    "\n",
    "# Close driver\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-length",
   "metadata": {},
   "source": [
    "## Creating screenshots from a website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome-Driver\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Website to scrape\n",
    "driver.get('https://store.dji.com')\n",
    "\n",
    "# Screenshot\n",
    "driver.save_screenshot('screenshot.png')\n",
    "\n",
    "# Plot image\n",
    "img = mpimg.imread('screenshot.png')\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis('off')\n",
    "imgplot = plt.imshow(img)\n",
    "\n",
    "# Close driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-onion",
   "metadata": {},
   "source": [
    "## Locating elements\n",
    "\n",
    "There are different methods available in the Selenium API to select elements on the page. You can use:\n",
    "\n",
    "- Name\n",
    "- Tag name\n",
    "- Class name\n",
    "- ID\n",
    "- XPath\n",
    "- CSS selectors\n",
    "\n",
    "Use the inspect element function in Chrome to get these infos:\n",
    "https://www.hostinger.com/tutorials/website/how-to-inspect-and-change-style-using-google-chrome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcf629c",
   "metadata": {},
   "source": [
    "### Locating elements using XPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome-Driver\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Website to scrape\n",
    "driver.get('https://store.dji.com')\n",
    "\n",
    "# Find element using xpath\n",
    "text = driver.find_element(By.XPATH, '/html/body').text\n",
    "print(text[:50])\n",
    "\n",
    "# Close driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee9525e",
   "metadata": {},
   "source": [
    "### Locating elements on https://www.autoscout24.ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1b855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change options to regular mode\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "# Chrome-Driver\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Website to scrape\n",
    "url = 'https://www.autoscout24.ch/de/s/mk-vw?pagination%5Bpage%5D=1'\n",
    "driver.get(url)\n",
    "\n",
    "# Get webpage number from url\n",
    "pattern = r'=(.*)'\n",
    "page = re.search(pattern, url)\n",
    "\n",
    "# Get the full content of the website\n",
    "source = driver.page_source\n",
    "\n",
    "# Close driver\n",
    "driver.close()\n",
    "\n",
    "# Parse HTML content with BeautifulSoup\n",
    "soup = BeautifulSoup(source, 'html.parser')\n",
    "\n",
    "# Get links\n",
    "links = []\n",
    "link_elements = soup.find_all(class_='css-qqdlpa')\n",
    "for element in link_elements:\n",
    "    links.append('https://www.autoscout24.ch' + element['href'])\n",
    "\n",
    "# Get types\n",
    "types_elements = soup.find_all(class_='chakra-heading css-svmyrf')\n",
    "types = [element.text for element in types_elements]\n",
    "\n",
    "# Get prices\n",
    "prices_elements = soup.find_all(class_='chakra-text css-bwl0or')\n",
    "prices = [element.text for element in prices_elements]\n",
    "\n",
    "# Dataframe\n",
    "df = pd.DataFrame({ 'Page': page.group(1),\n",
    "                    'Type': types,\n",
    "                    'Price': prices,\n",
    "                    'Weblink': links})\n",
    "\n",
    "# Save to file\n",
    "df.to_csv('autoscout24.csv', sep=\";\", index=False)\n",
    "\n",
    "# Show file\n",
    "with open('autoscout24.csv') as table_file:\n",
    "    tab = from_csv(table_file, delimiter=';')\n",
    "    \n",
    "    # Set the alignment for all columns to 'l' (left-align)\n",
    "    for field_name in tab.field_names:\n",
    "        tab.align[field_name] = 'l'\n",
    "    \n",
    "    print(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c713db",
   "metadata": {},
   "source": [
    "### Locating elements using tag names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome-Driver\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Website to scrape\n",
    "driver.get('https://bienen.ch')\n",
    "\n",
    "# Find element using tag names\n",
    "text = driver.find_element(By.TAG_NAME, 'h3').text\n",
    "print(text)\n",
    "\n",
    "# Close driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-relations",
   "metadata": {},
   "source": [
    "## Sent and submit text on Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome-Driver\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Website to scrape\n",
    "driver.get('https://de.wikipedia.org')\n",
    "\n",
    "# Fill in the search text\n",
    "text_to_send = 'Currywurst'\n",
    "element = driver.find_element(By.XPATH, '/html/body/div[4]/div[1]/div[2]/div/form/div/input[1]')\n",
    "element.send_keys(text_to_send)\n",
    "\n",
    "# Submit search text\n",
    "element.submit()\n",
    "\n",
    "# Extract text\n",
    "element = driver.find_element(By.TAG_NAME, 'p').text\n",
    "print(element)\n",
    "\n",
    "# Wait until the website is showing up\n",
    "time.sleep(5)\n",
    "\n",
    "# Click link to image on page found\n",
    "driver.find_element(By.XPATH, '/html/body/div[3]/div[3]/div[5]/div[1]/figure[1]/a/img').click()\n",
    "\n",
    "# Screenshot\n",
    "time.sleep(5)\n",
    "driver.save_screenshot('screenshot.png')\n",
    "\n",
    "# Close driver\n",
    "driver.close()\n",
    "\n",
    "# Plot image\n",
    "img = mpimg.imread('screenshot.png')\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.axis('off')\n",
    "imgplot = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-texas",
   "metadata": {},
   "source": [
    "## Pagination handling on https://www.minergie.ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome-Driver\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# Open file-connection\n",
    "MyFile = open('minergie_objects.txt', 'w', encoding='utf-8')\n",
    "\n",
    "obj = {}    \n",
    "\n",
    "# Loop through first 5 pages and save objects to file\n",
    "for i in range(5):\n",
    "    \n",
    "    # Generating URLs using page numbers\n",
    "    url = str('https://www.minergie.ch/de/gebaeude/gebaeudeliste/?canton=&country=&zip_place=&street_nr=&gid=&participator=&typeofuse=&constructiontype=&year=&sortby=date_asc&numres=12&p=' + str(i+1))\n",
    "    time.sleep(1)\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Click 'I agree' button for cookie-management on first page\n",
    "    if i == 1:\n",
    "        driver.find_element(By.XPATH, '/html/body/div[2]/div[1]/div/div[3]/div[1]/button[3]').click()\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    print(str('--------- Page:' + str(i+1) + '-------------------------------'))\n",
    "    \n",
    "    for n in range(12):\n",
    "        \n",
    "        path = str('/html/body/div[1]/div[4]/div[7]/div/div[' + str(n+1) + ']')\n",
    "\n",
    "        obj['Object'] = driver.find_element(By.XPATH, path).text\n",
    "        obj['Object'] = obj['Object'].replace(\"\\n\", \"\")\n",
    "        print(obj['Object'])\n",
    "        \n",
    "        # Write to file\n",
    "        MyFile.write(obj['Object'] + \"\\n\")\n",
    "        \n",
    "# Close file-connection\n",
    "MyFile.close()\n",
    "\n",
    "# Close driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-campus",
   "metadata": {},
   "source": [
    "## OpenStreetMap search location example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome driver\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "driver.get('https://www.openstreetmap.org/#map=9/46.7054/8.0283')\n",
    "time.sleep(2)\n",
    "\n",
    "# Submit address\n",
    "element = driver.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/form[1]/div/div[1]/div/input[1]')\n",
    "element.send_keys(\"Melchsee-Frutt\")\n",
    "element.send_keys(Keys.RETURN)\n",
    "time.sleep(2)\n",
    "\n",
    "# Click info boxes\n",
    "try:\n",
    "    # Click 1st info-box\n",
    "    info = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div/div[1]/div[5]/div[1]/div/button'))) \n",
    "    info.click()\n",
    "\n",
    "    # Click 2nd info-box\n",
    "    info = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div/div[1]/div[6]/div[1]/div/button'))) \n",
    "    info.click()\n",
    "\n",
    "    # Click 3rd info-box\n",
    "    info = WebDriverWait(driver, 2).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div/div[1]/div[7]/button')))\n",
    "    info.click()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Screenshot of map\n",
    "driver.save_screenshot('screenshot.png')\n",
    "img = mpimg.imread('screenshot.png')\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.axis('off')\n",
    "imgplot = plt.imshow(img)\n",
    "\n",
    "# Close driver\n",
    "driver.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccf11660",
   "metadata": {},
   "source": [
    "### Jupyter notebook --footer info-- (please always provide this at the end of each notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94655a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import socket\n",
    "from platform import python_version\n",
    "from datetime import datetime\n",
    "\n",
    "print('-----------------------------------')\n",
    "print(os.name.upper())\n",
    "print(platform.system(), '|', platform.release())\n",
    "print('Datetime:', datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print('Python Version:', python_version())\n",
    "print('-----------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "18632da57c1a416bf8be4aa27ba4ca7c1f66541805f18b0825a162dab4e44f29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
